{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d675912-56ac-4d7b-8ff1-2f9cce8b289b",
   "metadata": {},
   "source": [
    "### 1. 선형화귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f9ecc-4d2a-4182-89c0-99ceef156291",
   "metadata": {},
   "source": [
    "#### 예제: 데이터의 sqft_living(주거공간의 평방피트)를 독립변수, price를 종속변수로 설정하여 단순선형회귀분석을 실시한 후, 추정되는 회귀모형에 대해 해석하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f348e7b-9da2-4801-bd08-cb82d3fc0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "f_path = \n",
    "data = pd.read_csv(f_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba38b16-4d8d-4c9a-8898-b3edb42ee14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_y = \n",
    "col_x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9150692-5917-466a-bd02-8c82854e7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[col_y, col_x]]\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36719c3f-eab7-4f4e-adc2-0acb408a59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "#변수할당\n",
    "y = data[col_y]\n",
    "x = data[[col_x]]\n",
    "#단순 선형회귀 모형 적합\n",
    "lr = ols(f'{col_y}~{col_x}', data=data).fit()\n",
    "y_pred = lr.predict(x)\n",
    "#시각화\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x,y_pred, color='red')\n",
    "plt.xlabel(f'{col_x}', fontsize=10)\n",
    "plt.ylabel(f'{col_y}', fontsize=10)\n",
    "plt.title('Linear Regression Result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59477c-2ec9-4a71-96ee-71710cb8afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prob(F-statistic) 값이 F통계량으로\n",
    "귀무가설 : 회귀모형은 유의하지 않다\n",
    "대립가설 : 회귀모형은 유의하다\n",
    "'''\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ade55-22d8-4eaf-ad82-b49227768527",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr.f_pvalue < 0.05:\n",
    "    print('대립가설 채택, 회귀모형은 유의하다')\n",
    "    print(f'결정계수 R2은 {lr.rsquared}이다.')\n",
    "    print(f'결론, 전체 데이터의 {lr.rsquared*100}%를 설명하는 회귀식을 구할 수 있다.')\n",
    "    #lr.summary()의 coef열의 intercept 값은 상수값, col_x명의 값은 기울기 값으로 사용 가능하다.\n",
    "else:\n",
    "    print('귀무가설 채택, 회귀모형은 유의하지 않다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd5040-7046-48b5-8c1a-b517d6437feb",
   "metadata": {},
   "source": [
    "### 2. 다중 선형회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d9be6-1ad4-4c8f-bad2-d226803988cc",
   "metadata": {},
   "source": [
    "#### 예제: 다중 선형회귀분석에서 다중공선성ㅇㄹ 제거하고 최적의 모델을 찾기 위해 변수선택법을 적용하여 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a86ec-58e9-4e39-951f-e04cdbf9069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f_path = \n",
    "data = pd.read_csv(f_path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef49e8e-141e-40ed-97b7-afd0730fbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_y = \n",
    "col_x1 = \n",
    "col_x2 = \n",
    "col_x3 = \n",
    "col_x4 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3813ff-2130-49d2-973a-431ee598a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "#ols모델 formula을 정의할 때, 일부 특수문자는 쓸수 없기 때문에, 컬럼 특수문자 제거\n",
    "data.columns = data.columns.str.replace(\".\",\"\")\n",
    "model = smf.ols(formula=f'{col_y}~{col_x1}+{col_x2}+{col_x3}+{col_x4}', data = data)\n",
    "result = model.fit()\n",
    "result.summary()\n",
    "'''\n",
    "1. Adf.R-squared값을 통해, 전체 데이터의 R2*100 % 설명가능함을 확인\n",
    "2. Prob(F-statistic)값을 통해, p-value로 0.05 이하 여부를 확인 후 이하이면, 회귀모형 유의 함\n",
    "3. (P>|t|) 값이 p-value 유의수준보다 높은 컬럼명을 제거 한 후 다시 모델을 돌려보는 방안 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d528e-4bdc-4954-82ea-d82899ae85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중공선성 파악을 위한 상관관계 확인\n",
    "data[[col_x1, col_x2, col_x3, col_x4]].corr()\n",
    "'''\n",
    "플러스/마이너스 포함하여 0.9이상인 값의 다중공선성 변수를 확인 한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011d7d8-5b6f-43f0-a4a3-7e08a84cef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF값을 구해보자\n",
    "'''\n",
    "vif = 1/(1-r2)로 VIF가 10 이상인 경우 일반적으로 다중공선성이 있는 변수라고 판단\n",
    "'''\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_infuence import variance_inflation_factor\n",
    "#독립변수와 종속변수를 데이터프레임으로 나누어 저장하는 함수\n",
    "y, x = dmatrices(formula=f'{col_y}~{col_x1}+{col_x2}+{col_x3}+{col_x4}', data = data, return_type='dataframe')\n",
    "#독립변수끼리의 vif값을 계산하여 데이터프레임으로 만드는 과정\n",
    "vif_list=[]\n",
    "for i in range(1,len(x.columns)):\n",
    "    vif_list.append([variance_inflation_factor(x.values, i), x.columns[i])\n",
    "pd.DataFrame(vif_list, columns=['vif', 'variable'])\n",
    "'''\n",
    "vif가 가장 높은 variable인 컬러명을 제거대상으로 함\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90ad07-60ef-4c41-a0bf-20838a68f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 summary()를 다시 확인해 본다.\n",
    "model = smf.ols(formula = f'{col_y}~{col_x1}+{col_x2}+{col_x3}', data=data)\n",
    "result = model.fit()\n",
    "result.summary()\n",
    "'''\n",
    "1. Adf.R-squared값을 통해, 전체 데이터의 R2*100 % 설명가능함을 확인\n",
    "2. Prob(F-statistic)값을 통해, p-value로 0.05 이하 여부를 확인 후 이하이면, 회귀모형 유의 함\n",
    "3. (P>|t|) 값이 p-value 유의수준보다 높은 컬럼명을 제거 한 후 다시 모델을 돌려보는 방안 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35b514-0042-42c8-b729-0d7ebd64990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수 중 유이한 변수를 고르고, 모델의 성능을 최적화시키는 변수선택법을 진행\n",
    "import time\n",
    "import itertools\n",
    "def processSubset(x,y,feature_set):\n",
    "'''\n",
    "AIC는 모델의 성능지표로서 MSE에 변수 수만큼 penalty를 주는 것으로 AIC 값이 낮을 수록 모델 적합도가 좋다\n",
    "'''\n",
    "    model = sm.OLS(y,x[list(feature_set)]) #Modeling\n",
    "    regr = model.fit() \n",
    "    AIC = regr.aic # 모델의 AIC\n",
    "    return {\"model\":regr, \"aic\":AIC}\n",
    "\n",
    "#전진선택법\n",
    "def forward(x,y,predictors):\n",
    "    col_x='Intercept'\n",
    "    #데이터 변수들이 미리 정의된 predictors에 있는지 없는지 확인 및 분류\n",
    "    remaining_predictors = [p for p in x.columns.difference([col_x])\n",
    "                            if p not in predictors]\n",
    "    results = []\n",
    "    for p in remainig_predictors:\n",
    "        results.append(precessSubset(x=x,y=y,feature_set=predictors+[p]+[col_x]))\n",
    "    #데이터프레임으로 변환\n",
    "    models=pd.DataFrame(results)\n",
    "    #AIC가 가장 낮은 것을 선택\n",
    "    best_model = models.loc[models['AIC'].argmin()]#index\n",
    "    print('Processed', models.shape[0], 'models on', len(predictors)+1, 'predictors in')\n",
    "    print('Selected predictors:', best_model['model'].model.exog_names, 'AIC:', best_model[0])\n",
    "    return best_model\n",
    "\n",
    "#후진소거법\n",
    "def backward(x,y,predictors):\n",
    "    col_x='Intercept'\n",
    "    tic=time.time()\n",
    "    results=[]\n",
    "    #데이터 변수들이 미리 정의된 predictors 조합 확인\n",
    "    for combo in itertools.combinations(predictors, len(predictors) -1):\n",
    "        results.append(processSubset(x=x, y=y, feature_set=list(combo)+[col_x]))\n",
    "    #데이터프레임으로 변환\n",
    "    models=pd.DataFrame(results)\n",
    "    #가장 낮은 AIC를 가진 모델을 선택\n",
    "    best_model = models.loc[models['AIC'].argmin()]\n",
    "    toc = time.time()\n",
    "    print('Processed', models.shape[0], 'models on',\n",
    "          len(predictors) -1, 'predictors in', (toc-tic))\n",
    "    print('Selected predictors:', best_model['model'].model.exog_names, 'AIC:', best_model[0])\n",
    "    return best_model\n",
    "    \n",
    "#단계적 선택법\n",
    "def Stepwise_model(x,y):\n",
    "    stepmodels = pd.DataFrame(columns=['AIC', \"model\"])\n",
    "    tic=time.time()\n",
    "    predictors = []\n",
    "    smodel_before = processSubset(x,y,predictors+['Intercept'])['AIC']\n",
    "    for i in range(1, len(x.columns.difference(['Intercept']))+1):\n",
    "        forward_result=forward(x=x, y=y, predictors=predictors)\n",
    "        print('forward')\n",
    "        stepmodels.loc[i]=forward_result\n",
    "        predictors = stemodels.loc[i]['mdoel'].model.exog_names\n",
    "        predictors = [k for k in predictors if k!='Intercept']\n",
    "        Backward_result = bacward(x=x, y=y, predictors=predictors)\n",
    "\n",
    "        if Backward_result['Aic']<Forward_result['AIC']:\n",
    "            stepmodels.loc[i] = Backward_result\n",
    "            predictors = stepmodels.loc[i]['model'].model.xeog_names\n",
    "            smodel_before = stepmodels.loc[i]['AIC']\n",
    "            predictors = [k for k in predictors if k='Intercept']\n",
    "            print('backward')\n",
    "\n",
    "        if stepmodels.loc[i]['AIC']>smodel_before:\n",
    "            break\n",
    "        else:\n",
    "            smodel_before = stepmodels.loc[i]['AIC']\n",
    "    toc = time.time()\n",
    "    print('total elapsed time: ', (toc-tic), 'seconds.')\n",
    "    return (stepmodels['model'][len(stepmodels['model'])])\n",
    "\n",
    "stepwise_best_model = stepwise_model(x=x, y=y)\n",
    "\n",
    "\n",
    "stepwise_best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd45d29-5fac-41c1-9fa2-f98e4f9dc758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2897673-bc8f-4d47-960f-4ea5320969d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98611683-bc52-4c37-b142-efe6e2dc631e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
